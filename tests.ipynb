{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from datamodules.preprocessing import data_preprocessing\n",
    "from utils.config_utils import get_config_with_dirs\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 490513/490513 [03:16<00:00, 2491.56it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m (data_conf, model_conf, learning_conf, params_conf), _ \u001b[39m=\u001b[39m get_config_with_dirs(\u001b[39m'\u001b[39m\u001b[39mconfig.ini\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m original_df, (train_sequences, val_sequences, test_sequences) \u001b[39m=\u001b[39m data_preprocessing(\n\u001b[0;32m      4\u001b[0m     data_conf,\n\u001b[0;32m      5\u001b[0m     model_conf,\n\u001b[0;32m      6\u001b[0m     params_conf\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\n.Belousov\\Documents\\work\\nlp-transactions-project\\NLP-Transactions\\datamodules\\preprocessing\\preprocessing.py:15\u001b[0m, in \u001b[0;36mdata_preprocessing\u001b[1;34m(data_conf, model_conf, params_conf)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_preprocessing\u001b[39m(\n\u001b[0;32m     10\u001b[0m         data_conf: DataConf,\n\u001b[0;32m     11\u001b[0m         model_conf: ModelConf,\n\u001b[0;32m     12\u001b[0m         params_conf: ClassificationParamsConf\n\u001b[0;32m     13\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[pd\u001b[39m.\u001b[39mDataFrame, Tuple[pd\u001b[39m.\u001b[39mDataFrame, pd\u001b[39m.\u001b[39mDataFrame, pd\u001b[39m.\u001b[39mDataFrame]]:\n\u001b[0;32m     14\u001b[0m     \u001b[39mif\u001b[39;00m data_conf\u001b[39m.\u001b[39mdataset \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrosbank\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 15\u001b[0m         \u001b[39mreturn\u001b[39;00m rb_preprocessing(data_conf, model_conf, params_conf)\n\u001b[0;32m     16\u001b[0m     \u001b[39melif\u001b[39;00m data_conf\u001b[39m.\u001b[39mdataset \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtinkoff\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     17\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mDataset preprocessing not implemented yet!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\n.Belousov\\Documents\\work\\nlp-transactions-project\\NLP-Transactions\\datamodules\\preprocessing\\rosbank_preprocessing.py:71\u001b[0m, in \u001b[0;36mrb_preprocessing\u001b[1;34m(data_conf, model_conf, params_conf)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m params_conf\u001b[39m.\u001b[39mpretrained_embed:\n\u001b[0;32m     66\u001b[0m     weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m     67\u001b[0m         data_conf\u001b[39m.\u001b[39memb_dir,\n\u001b[0;32m     68\u001b[0m         \u001b[39m'\u001b[39m\u001b[39membedding_weights\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     69\u001b[0m         model_conf\u001b[39m.\u001b[39memb_weights_name\n\u001b[0;32m     70\u001b[0m     ))\n\u001b[1;32m---> 71\u001b[0m mcc_embeddings \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mEmbedding(\n\u001b[0;32m     72\u001b[0m     params_conf\u001b[39m.\u001b[39;49mmcc_vocab_size \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m     73\u001b[0m     params_conf\u001b[39m.\u001b[39;49mmcc_embed_size,\n\u001b[0;32m     74\u001b[0m     padding_idx\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m\n\u001b[0;32m     75\u001b[0m )\u001b[39m.\u001b[39;49mto(model_conf\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m     76\u001b[0m amnt_embeddings \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mEmbedding(\n\u001b[0;32m     77\u001b[0m     params_conf\u001b[39m.\u001b[39mamnt_bins \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m     78\u001b[0m     params_conf\u001b[39m.\u001b[39mamnt_emb_size,\n\u001b[0;32m     79\u001b[0m     padding_idx\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m     80\u001b[0m )\u001b[39m.\u001b[39mto(model_conf\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     82\u001b[0m mcc_embeddings\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m weights[\u001b[39m'\u001b[39m\u001b[39mmccs\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\n.Belousov\\Anaconda3\\envs\\nlp-transactions\\lib\\site-packages\\torch\\nn\\modules\\module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32mc:\\Users\\n.Belousov\\Anaconda3\\envs\\nlp-transactions\\lib\\site-packages\\torch\\nn\\modules\\module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\n.Belousov\\Anaconda3\\envs\\nlp-transactions\\lib\\site-packages\\torch\\nn\\modules\\module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "File \u001b[1;32mc:\\Users\\n.Belousov\\Anaconda3\\envs\\nlp-transactions\\lib\\site-packages\\torch\\cuda\\__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "(data_conf, model_conf, learning_conf, params_conf), _ = get_config_with_dirs('config.ini')\n",
    "\n",
    "original_df, (train_sequences, val_sequences, test_sequences) = data_preprocessing(\n",
    "    data_conf,\n",
    "    model_conf,\n",
    "    params_conf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>small_group</th>\n",
       "      <th>amount_rur_kb</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>average_amt</th>\n",
       "      <th>top_mcc_1</th>\n",
       "      <th>top_mcc_2</th>\n",
       "      <th>top_mcc_3</th>\n",
       "      <th>gc_id</th>\n",
       "      <th>target_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>client_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>[10, 10, 3, 142, 3, 2, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>[37, 50, 48, 47, 47, 2, 46, 50, 49, 50, 49, 49...</td>\n",
       "      <td>[7, 8, 0, 6, 6, 0, 4, 10, 10, 6, 6, 0, 14]</td>\n",
       "      <td>[12, 6, 11, 3, 3, 5, 5, 18, 18, 20, 20, 24, 7]</td>\n",
       "      <td>[5, 0, 5, 0, 0, 2, 2, 3, 3, 5, 5, 2, 2]</td>\n",
       "      <td>[11, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6]</td>\n",
       "      <td>[44, 43, 44, 44, 44, 44, 44, 43, 43, 43, 43, 4...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "      <td>[13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...</td>\n",
       "      <td>[1, 4, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 8]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>[22, 2, 22, 97, 2, 3, 1, 1, 1, 22, 1, 3, 2, 61...</td>\n",
       "      <td>[33, 33, 17, 11, 28, 44, 21, 18, 15, 19, 16, 5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[27, 28, 29, 29, 31, 4, 5, 6, 6, 7, 7, 9, 9, 9...</td>\n",
       "      <td>[5, 6, 0, 0, 2, 6, 0, 1, 1, 2, 2, 4, 4, 4, 5, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "      <td>[43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 4...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 205, 3, 3, 3...</td>\n",
       "      <td>[50, 36, 42, 50, 50, 20, 20, 20, 20, 20, 49, 3...</td>\n",
       "      <td>[7, 7, 11, 7, 7, 11, 11, 11, 11, 11, 11, 0, 7,...</td>\n",
       "      <td>[21, 21, 21, 22, 23, 27, 27, 27, 27, 27, 27, 2...</td>\n",
       "      <td>[2, 2, 2, 3, 4, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, ...</td>\n",
       "      <td>[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...</td>\n",
       "      <td>[44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 4...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>[23, 3, 3, 13, 22, 13, 22, 3, 13, 3, 22, 22, 1...</td>\n",
       "      <td>[29, 31, 43, 19, 10, 14, 18, 31, 18, 31, 13, 1...</td>\n",
       "      <td>[0, 0, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[1, 1, 1, 3, 3, 3, 4, 5, 5, 6, 6, 7, 7, 9, 9, ...</td>\n",
       "      <td>[5, 5, 5, 0, 0, 0, 1, 2, 2, 3, 3, 4, 4, 6, 6, ...</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "      <td>[44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 4...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>[26, 39, 13, 3, 55, 16, 2, 40, 40, 43, 46, 16,...</td>\n",
       "      <td>[24, 46, 17, 48, 46, 48, 38, 44, 44, 44, 43, 4...</td>\n",
       "      <td>[0, 0, 0, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[19, 19, 19, 19, 20, 20, 20, 20, 20, 21, 21, 2...</td>\n",
       "      <td>[4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 0, 0, 0, ...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "      <td>[43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 4...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>[25, 78, 27, 5, 27, 19, 2, 27, 3, 27, 2, 14, 2...</td>\n",
       "      <td>[35, 35, 33, 35, 15, 27, 35, 13, 43, 24, 29, 1...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 9, 9, 9, 10, 10...</td>\n",
       "      <td>[3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 6, 6, 6, 0, 0, ...</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 4...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...</td>\n",
       "      <td>[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>[3, 3, 25, 2, 2, 2, 71, 71, 2, 58, 5, 5, 43, 2...</td>\n",
       "      <td>[6, 6, 40, 38, 27, 22, 29, 34, 19, 24, 19, 28,...</td>\n",
       "      <td>[8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[23, 23, 24, 24, 24, 24, 25, 25, 25, 26, 26, 2...</td>\n",
       "      <td>[4, 4, 5, 5, 5, 5, 6, 6, 6, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "      <td>[43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 4...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...</td>\n",
       "      <td>[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9679</th>\n",
       "      <td>[78, 78, 78, 78, 53, 78, 78, 78, 78, 78, 78, 7...</td>\n",
       "      <td>[2, 2, 2, 39, 1, 1, 4, 3, 3, 6, 2, 6, 7, 17, 3...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[6, 11, 11, 11, 12, 16, 16, 16, 16, 17, 17, 17...</td>\n",
       "      <td>[1, 6, 6, 6, 0, 4, 4, 4, 4, 5, 5, 5, 0, 0, 1, ...</td>\n",
       "      <td>[12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...</td>\n",
       "      <td>[44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 4...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>[2, 2, 63, 68, 68, 4, 2, 4, 17, 2, 2, 27, 19, ...</td>\n",
       "      <td>[16, 12, 23, 33, 33, 16, 42, 29, 22, 34, 14, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[7, 10, 10, 10, 10, 11, 11, 11, 12, 13, 14, 14...</td>\n",
       "      <td>[4, 0, 0, 0, 0, 1, 1, 1, 2, 3, 4, 4, 4, 5, 6, ...</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 4...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...</td>\n",
       "      <td>[9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>[73, 22, 2, 2, 22, 22, 26, 22, 29, 16, 55, 3, ...</td>\n",
       "      <td>[6, 27, 29, 11, 8, 9, 27, 12, 25, 48, 48, 46, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 0,...</td>\n",
       "      <td>[13, 13, 13, 15, 15, 16, 16, 16, 17, 17, 17, 1...</td>\n",
       "      <td>[0, 0, 0, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 6, ...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 4...</td>\n",
       "      <td>[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "      <td>[13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...</td>\n",
       "      <td>[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3804 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 small_group  \\\n",
       "client_id                                                      \n",
       "1700             [10, 10, 3, 142, 3, 2, 3, 3, 3, 3, 3, 3, 3]   \n",
       "902        [22, 2, 22, 97, 2, 3, 1, 1, 1, 22, 1, 3, 2, 61...   \n",
       "1820       [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 205, 3, 3, 3...   \n",
       "721        [23, 3, 3, 13, 22, 13, 22, 3, 13, 3, 22, 22, 1...   \n",
       "1842       [26, 39, 13, 3, 55, 16, 2, 40, 40, 43, 46, 16,...   \n",
       "...                                                      ...   \n",
       "4227       [25, 78, 27, 5, 27, 19, 2, 27, 3, 27, 2, 14, 2...   \n",
       "558        [3, 3, 25, 2, 2, 2, 71, 71, 2, 58, 5, 5, 43, 2...   \n",
       "9679       [78, 78, 78, 78, 53, 78, 78, 78, 78, 78, 78, 7...   \n",
       "2023       [2, 2, 63, 68, 68, 4, 2, 4, 17, 2, 2, 27, 19, ...   \n",
       "7702       [73, 22, 2, 2, 22, 22, 26, 22, 29, 16, 55, 3, ...   \n",
       "\n",
       "                                               amount_rur_kb  \\\n",
       "client_id                                                      \n",
       "1700       [37, 50, 48, 47, 47, 2, 46, 50, 49, 50, 49, 49...   \n",
       "902        [33, 33, 17, 11, 28, 44, 21, 18, 15, 19, 16, 5...   \n",
       "1820       [50, 36, 42, 50, 50, 20, 20, 20, 20, 20, 49, 3...   \n",
       "721        [29, 31, 43, 19, 10, 14, 18, 31, 18, 31, 13, 1...   \n",
       "1842       [24, 46, 17, 48, 46, 48, 38, 44, 44, 44, 43, 4...   \n",
       "...                                                      ...   \n",
       "4227       [35, 35, 33, 35, 15, 27, 35, 13, 43, 24, 29, 1...   \n",
       "558        [6, 6, 40, 38, 27, 22, 29, 34, 19, 24, 19, 28,...   \n",
       "9679       [2, 2, 2, 39, 1, 1, 4, 3, 3, 6, 2, 6, 7, 17, 3...   \n",
       "2023       [16, 12, 23, 33, 33, 16, 42, 29, 22, 34, 14, 2...   \n",
       "7702       [6, 27, 29, 11, 8, 9, 27, 12, 25, 48, 48, 46, ...   \n",
       "\n",
       "                                                        hour  \\\n",
       "client_id                                                      \n",
       "1700              [7, 8, 0, 6, 6, 0, 4, 10, 10, 6, 6, 0, 14]   \n",
       "902        [0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1820       [7, 7, 11, 7, 7, 11, 11, 11, 11, 11, 11, 0, 7,...   \n",
       "721        [0, 0, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "1842       [0, 0, 0, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "...                                                      ...   \n",
       "4227       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "558        [8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9679       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2023       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7702       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 0,...   \n",
       "\n",
       "                                                         day  \\\n",
       "client_id                                                      \n",
       "1700          [12, 6, 11, 3, 3, 5, 5, 18, 18, 20, 20, 24, 7]   \n",
       "902        [27, 28, 29, 29, 31, 4, 5, 6, 6, 7, 7, 9, 9, 9...   \n",
       "1820       [21, 21, 21, 22, 23, 27, 27, 27, 27, 27, 27, 2...   \n",
       "721        [1, 1, 1, 3, 3, 3, 4, 5, 5, 6, 6, 7, 7, 9, 9, ...   \n",
       "1842       [19, 19, 19, 19, 20, 20, 20, 20, 20, 21, 21, 2...   \n",
       "...                                                      ...   \n",
       "4227       [6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 9, 9, 9, 10, 10...   \n",
       "558        [23, 23, 24, 24, 24, 24, 25, 25, 25, 26, 26, 2...   \n",
       "9679       [6, 11, 11, 11, 12, 16, 16, 16, 16, 17, 17, 17...   \n",
       "2023       [7, 10, 10, 10, 10, 11, 11, 11, 12, 13, 14, 14...   \n",
       "7702       [13, 13, 13, 15, 15, 16, 16, 16, 17, 17, 17, 1...   \n",
       "\n",
       "                                                 day_of_week  \\\n",
       "client_id                                                      \n",
       "1700                 [5, 0, 5, 0, 0, 2, 2, 3, 3, 5, 5, 2, 2]   \n",
       "902        [5, 6, 0, 0, 2, 6, 0, 1, 1, 2, 2, 4, 4, 4, 5, ...   \n",
       "1820       [2, 2, 2, 3, 4, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, ...   \n",
       "721        [5, 5, 5, 0, 0, 0, 1, 2, 2, 3, 3, 4, 4, 6, 6, ...   \n",
       "1842       [4, 4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 0, 0, 0, ...   \n",
       "...                                                      ...   \n",
       "4227       [3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 6, 6, 6, 0, 0, ...   \n",
       "558        [4, 4, 5, 5, 5, 5, 6, 6, 6, 0, 0, 0, 1, 1, 1, ...   \n",
       "9679       [1, 6, 6, 6, 0, 4, 4, 4, 4, 5, 5, 5, 0, 0, 1, ...   \n",
       "2023       [4, 0, 0, 0, 0, 1, 1, 1, 2, 3, 4, 4, 4, 5, 6, ...   \n",
       "7702       [0, 0, 0, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 6, ...   \n",
       "\n",
       "                                                       month  \\\n",
       "client_id                                                      \n",
       "1700                [11, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6]   \n",
       "902        [5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...   \n",
       "1820       [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...   \n",
       "721        [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...   \n",
       "1842       [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
       "...                                                      ...   \n",
       "4227       [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "558        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...   \n",
       "9679       [12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1...   \n",
       "2023       [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "7702       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "\n",
       "                                                 average_amt  \\\n",
       "client_id                                                      \n",
       "1700       [44, 43, 44, 44, 44, 44, 44, 43, 43, 43, 43, 4...   \n",
       "902        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 4...   \n",
       "1820       [44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 4...   \n",
       "721        [44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 4...   \n",
       "1842       [43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 4...   \n",
       "...                                                      ...   \n",
       "4227       [42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 4...   \n",
       "558        [43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 4...   \n",
       "9679       [44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 4...   \n",
       "2023       [42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 4...   \n",
       "7702       [43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 4...   \n",
       "\n",
       "                                                   top_mcc_1  \\\n",
       "client_id                                                      \n",
       "1700                 [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]   \n",
       "902        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "1820       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "721        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "1842       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "...                                                      ...   \n",
       "4227       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "558        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "9679       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "2023       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "7702       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...   \n",
       "\n",
       "                                                   top_mcc_2  \\\n",
       "client_id                                                      \n",
       "1700                 [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]   \n",
       "902        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "1820       [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "721        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "1842       [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "...                                                      ...   \n",
       "4227       [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "558        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "9679       [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "2023       [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "7702       [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...   \n",
       "\n",
       "                                                   top_mcc_3  \\\n",
       "client_id                                                      \n",
       "1700       [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...   \n",
       "902        [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...   \n",
       "1820       [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...   \n",
       "721        [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...   \n",
       "1842       [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...   \n",
       "...                                                      ...   \n",
       "4227       [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...   \n",
       "558        [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...   \n",
       "9679       [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...   \n",
       "2023       [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...   \n",
       "7702       [13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 1...   \n",
       "\n",
       "                                                       gc_id  target_flag  \n",
       "client_id                                                                  \n",
       "1700                 [1, 4, 5, 5, 5, 5, 5, 7, 7, 7, 7, 7, 8]            3  \n",
       "902        [7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...            2  \n",
       "1820       [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...            3  \n",
       "721        [5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, ...            5  \n",
       "1842       [7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...           19  \n",
       "...                                                      ...          ...  \n",
       "4227       [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, ...           27  \n",
       "558        [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...            3  \n",
       "9679       [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, ...           78  \n",
       "2023       [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, ...           19  \n",
       "7702       [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...           26  \n",
       "\n",
       "[3804 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = (torch.ones((3, 10)), torch.ones((4, 10)))\n",
    "\n",
    "pad_sequence(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
